{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCj9zSdPlgJU",
        "outputId": "a41b1ecd-102f-441d-94ef-23da82ddf2c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git\n",
        "!pip install snscrape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OQTAh8imwlE",
        "outputId": "b6173da8-746b-4e1f-931f-42637a0b7554"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
            "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to /tmp/pip-req-build-cxy6zrq0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/JustAnotherArchivist/snscrape.git /tmp/pip-req-build-cxy6zrq0\n",
            "  Resolved https://github.com/JustAnotherArchivist/snscrape.git to commit 99050710d78b22b5c605b08d85c1513d9db44323\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tweet object attributes\n",
        "# Index(['card', 'cashtags', 'content', 'conversationId', 'coordinates', 'date',\n",
        "#        'hashtags', 'id', 'inReplyToTweetId', 'inReplyToUser', 'json', 'lang',\n",
        "#        'likeCount', 'links', 'media', 'mentionedUsers', 'outlinks',\n",
        "#        'outlinksss', 'place', 'quoteCount', 'quotedTweet', 'rawContent',\n",
        "#        'renderedContent', 'replyCount', 'retweetCount', 'retweetedTweet',\n",
        "#        'source', 'sourceLabel', 'sourceUrl', 'tcooutlinks', 'tcooutlinksss',\n",
        "#        'url', 'user', 'username', 'vibe', 'viewCount'],\n",
        "#       dtype='object')"
      ],
      "metadata": {
        "id": "UYVkpZ8Fv_2e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "\n",
        "# change the values after since and until in query\n",
        "query = '(chatgpt OR #chatgpt) AND lang:en AND since:2023-03-02 AND until:2023-03-03'\n",
        "max_count = 10000\n",
        "\n",
        "tweets_list = []\n",
        "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
        "  if (i % 100) == 0:\n",
        "    print('count: ', i)\n",
        "  countryCode = tweet.place.countryCode if tweet.place is not None else None\n",
        "  if i > max_count:\n",
        "      break\n",
        "  tweets_list.append([tweet.date, tweet.id, tweet.rawContent, countryCode])\n",
        "\n",
        "# Creating a dataframe from the tweets list above\n",
        "tweets_df = pd.DataFrame(tweets_list, columns=['datetime', 'id', 'content', 'countryCode'])\n",
        "tweets_df.head()\n",
        "tweets_df.to_csv('tweet_chatgpt.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uztWhmZ3n7af",
        "outputId": "5ce164c8-c63e-4637-a05d-5b243d0cc7a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count:  0\n",
            "count:  100\n",
            "count:  200\n",
            "count:  300\n",
            "count:  400\n",
            "count:  500\n",
            "count:  600\n",
            "count:  700\n",
            "count:  800\n",
            "count:  900\n",
            "count:  1000\n",
            "count:  1100\n",
            "count:  1200\n",
            "count:  1300\n",
            "count:  1400\n",
            "count:  1500\n",
            "count:  1600\n",
            "count:  1700\n",
            "count:  1800\n",
            "count:  1900\n",
            "count:  2000\n",
            "count:  2100\n",
            "count:  2200\n",
            "count:  2300\n",
            "count:  2400\n",
            "count:  2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seem not too useful\n",
        "# sntwitter.TwitterHashtagScraper('ChatGPT')"
      ],
      "metadata": {
        "id": "sXyM8UxTmtX9"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}
