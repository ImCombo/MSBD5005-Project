{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCj9zSdPlgJU",
        "outputId": "a41b1ecd-102f-441d-94ef-23da82ddf2c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OQTAh8imwlE",
        "outputId": "b6173da8-746b-4e1f-931f-42637a0b7554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
            "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to /tmp/pip-req-build-cxy6zrq0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/JustAnotherArchivist/snscrape.git /tmp/pip-req-build-cxy6zrq0\n",
            "  Resolved https://github.com/JustAnotherArchivist/snscrape.git to commit 99050710d78b22b5c605b08d85c1513d9db44323\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git\n",
        "!pip install snscrape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UYVkpZ8Fv_2e"
      },
      "outputs": [],
      "source": [
        "# Tweet object attributes\n",
        "# Index(['card', 'cashtags', 'content', 'conversationId', 'coordinates', 'date',\n",
        "#        'hashtags', 'id', 'inReplyToTweetId', 'inReplyToUser', 'json', 'lang',\n",
        "#        'likeCount', 'links', 'media', 'mentionedUsers', 'outlinks',\n",
        "#        'outlinksss', 'place', 'quoteCount', 'quotedTweet', 'rawContent',\n",
        "#        'renderedContent', 'replyCount', 'retweetCount', 'retweetedTweet',\n",
        "#        'source', 'sourceLabel', 'sourceUrl', 'tcooutlinks', 'tcooutlinksss',\n",
        "#        'url', 'user', 'username', 'vibe', 'viewCount'],\n",
        "#       dtype='object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uztWhmZ3n7af",
        "outputId": "5ce164c8-c63e-4637-a05d-5b243d0cc7a9"
      },
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pickle\n",
        "\n",
        "# change the values after since and until in query\n",
        "query = '(chatgpt OR #chatgpt) AND lang:en AND since:2023-03-01 AND until:2023-03-12'\n",
        "max_count = 1000\n",
        "\n",
        "tweets_dict = {}\n",
        "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
        "  tweets_dict[tweet.id] = tweet\n",
        "  if ((i + 1) % 500) == 0:\n",
        "    with open('tweet.pkl', 'wb') as f:\n",
        "      print('Saving at', i + 1, 'iterations')\n",
        "      pickle.dump(tweets_dict, f)\n",
        "  if i + 1 == max_count:\n",
        "    break\n",
        "\n",
        "print(f'Actual number of scrapped tweet: {len(tweets_dict)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXyM8UxTmtX9"
      },
      "outputs": [],
      "source": [
        "with open('tweets.pkl', 'rb') as f:\n",
        "    tweets_dict = pickle.load(f)\n",
        "\n",
        "for tid in tweets_dict:\n",
        "    tweet = tweets_dict[tid]\n",
        "    print(tweet.content, tweet.likeCount, tweet.replyCount, tweet.retweetCount, tweet.user)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pickle\n",
        "\n",
        "tweets_dict = {}\n",
        "month = str(3).zfill(2)\n",
        "\n",
        "# Force the scraper to get same number of tweet for each day\n",
        "for day in range(1, 16):\n",
        "  start = str(day).zfill(2)\n",
        "  end = str(day + 1).zfill(2)\n",
        "  save_location = 'tweets.pkl'\n",
        "  query = f'(chatgpt OR #chatgpt) AND lang:en AND since:2023-{month}-{start} AND until:2023-{month}-{end}'\n",
        "  day_count = 10000\n",
        "  \n",
        "  for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
        "    tweets_dict[tweet.id] = tweet\n",
        "    if ((i + 1) % 500) == 0:\n",
        "      with open(save_location, 'wb') as f:\n",
        "        print(f'Saving at {i + 1} iterations for 2023-{month}-{start}')\n",
        "        pickle.dump(tweets_dict, f)\n",
        "    if i + 1 == day_count:\n",
        "        break\n",
        "  \n",
        "print(f'Total actual number of scrapped tweet: {len(tweets_dict)}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
